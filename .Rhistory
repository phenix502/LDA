word[[1]][2]
word[1][3]
word[1][2]
unlist(word)
unlist(word)[1]
unlist(word)[2]
unlist(word)[3]
cor <- Corpus(VectorSource(word))
inspect(cor)
cor
cor.dtm <- DocumentTermMatrix(cor)
inspect(cor.dtm)
word
cor
cor[1]
inspect(cor[1])
cor.dtm
a <- word[[1]]
a
a[1]
b <-word[[2]]
a_b.dtm<- DocumentTermMatrix(Corpus(VectorSource(a,b)))
inspect(a_b.dtm)
cor.dtm
inspect(cor.dtm)
removeEnglish <- function(x){
gsub("\w","",x)
}
gsub("\\w","",x)
source('~/.active-rstudio-document')
song_two[2]
removeEnglish(song_two[2])
source('~/.active-rstudio-document')
removeEnglish(song_two[2])
source('~/.active-rstudio-document')
removeEnglish(song_two[2])
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
removeEnglish(song_two[2])
source('~/.active-rstudio-document')
removeEnglish(song_two[2])
song_two <- lapply(song_two, removeEnglish)
song_two
word <- lapply(song_two,segmentCN)
cor <- Corpus(VectorSource(word))
inspect(word)
inspect(cor)
cor.dtm <- DocumentTermMatrix(cor)
cor.dtm
inspect(cor.dtm)
findFreqTerms(cor.dtm,2,Inf)
termFreq(word)
termFreq(song_tow)
termFreq(song_two)
cor
inspect(cor.dtm)
cor.dtm <- DocumentTermMatrix(cor, control=(global = c(1, Inf)))
cor.dtm <- DocumentTermMatrix(cor, control= ( list(global = c(1, Inf)))
)
cor.dtm
cor.dtm <- DocumentTermMatrix(cor)
cor
inspect(cor)
inspect(crude)
word
word[[2]]
unlist(word[[2]])
word[[2]]
word[[2]][1]
inspect(cor.dtm)
cor.dtm <- DocumentTermMatrix(cor, control=list(wordLengths = c(2, Inf))
)
inspect(cor.dtm)
cor.dtm <- DocumentTermMatrix(cor, control=list(wordLengths = c(1, Inf)))
inspect(cor.dtm)
song <- output$songLyric
## 分词
song <- lapply(song, removeEnglish)
word <- lapply(song,segmentCN)
##形成语料库
cor <- Corpus(VectorSource(word))
## 文档-词矩阵 词的长度大于1就纳入矩阵
cor.dtm <- DocumentTermMatrix(cor, control=list(wordLengths = c(1, Inf)))
inspect(cor.dtm)
cor
cor.dtm
##取前面两首歌分析
song <- output$songLyric[1:10]
## 分词
song <- lapply(song, removeEnglish)
word <- lapply(song,segmentCN)
##形成语料库
cor <- Corpus(VectorSource(word))
## 文档-词矩阵 词的长度大于1就纳入矩阵
cor.dtm <- DocumentTermMatrix(cor, control=list(wordLengths = c(1, Inf)))
inspect(cor.dtm)
##取前面两首歌分析
song <- output$songLyric
## 分词
song <- lapply(song, removeEnglish)
word <- lapply(song,segmentCN)
##形成语料库
cor <- Corpus(VectorSource(word))
## 文档-词矩阵 词的长度大于1就纳入矩阵
cor.dtm <- DocumentTermMatrix(cor, control=list(wordLengths = c(1, Inf)))
##去掉稀疏矩阵中低频率的词
cor.dtm <- removeSparseTerms(cor.dtm, 0.99)
## 使得每一行至少有一个词不为0
rowTotals <- apply(cor.dtm, 1, sum)
cor.dtm <- cor.dtm[rowTotals > 0]
dim(cor.dtm)
inspect(cor.dtm)
result_LDA <- LDA(cor.dtm[1:250,],control = list(alpha = 0.1), k = 3)
post <- posterior(result_LDA, newdata = cor.dtm[-c(1:150),])
round(post$topics[1:5,],digits = 2)
get_terms(result_LDA, 5)
result_LDA <- LDA(cor.dtm[1:850,],control = list(alpha = 0.1), k = 3)
# jss_CTM <- CTM(cor.dtm[1:250], k = 10)
post <- posterior(result_LDA, newdata = cor.dtm[-c(1:150),])
round(post$topics[1:5,],digits = 2)
get_terms(result_LDA, 5)
mystopwords <- readLines("stopwords.txt",encoding = "UTF-8")
mystopwords <- readLines("stopwords.txt",encoding = "UTF-8")
cor.dtm <- DocumentTermMatrix(cor, control=list( wordLengths = c(1, Inf),stopwords=mystopwords ))
inspect(cor.dtm)
result_LDA <- LDA(cor.dtm[1:850,],control = list(alpha = 0.1), k = 3)
# jss_CTM <- CTM(cor.dtm[1:250], k = 10)
post <- posterior(result_LDA, newdata = cor.dtm[-c(1:150),])
round(post$topics[1:5,],digits = 2)
get_terms(result_LDA, 5)
<<<<<<< HEAD
ls()
docs()
docs
year
remove(year)
ls
ls()
tax.1
remove(tax.1,tax.2,tax.3,a,b,cor_test,dtm.test)
ls()
song.2<-output$songLyric
song.2<-output$songLyric[1:2]
song.2
unlist(song.2)
song.2<-unlist(lapply(song,removeEnglish))
song.2<-unlist(lapply(song,segmentCN))
library(Rwordseg)
song.2<-unlist(lapply(song,segmentCN))
song.2
cor.dtm
inspect(cor.dtm)
library(tm)
inspect(cor.dtm)
library(tm)
?DocumentTermMatrix
cor.dtm <- DocumentTermMatrix(cor, control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting=weightIfIdf ))
output$songLyric[[1]]
cor.dtm <- DocumentTermMatrix(cor, control=list( wordLengths = c(1, Inf),stopwords=mystopwords)
)
cor.dtm
new("TermDocMatrix", Data = cor.dtm, Weighting = weightTfIdf)
new(cor.dtm, Data = cor.dtm.new, Weighting = weightTfIdf)
cor.dtm <- DocumentTermMatrix(cor, control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
cor.dtm
inspect(cor.dtm)
inspect(cor.dtm[1:20])
cor.dtm <- removeSparseTerms(cor.dtm, 0.99)
rowTotals <- apply(cor.dtm, 1, sum)
cor.dtm <- cor.dtm[rowTotals > 0]
dim(cor.dtm)
dissimilarity(cor.dtm, method="cosine")
install.packages("proxy")
dissimilarity(cor.dtm, method="cosine")
?dissimilarity.TermDocumentMatrix
dissimilarity(t(cor.dtm), method="cosine")
output$songLyric[1]
output$songLyric[2]
library(RMongo)
str(dbGetQuery)
cor.beta <- Corpus(VectorSource(c(song.a,song.b))
)
song.a <-  output$songLyric[1]
song.b <-  output$songLyric[2]
cor.beta <- Corpus(VectorSource(c(song.a,song.b)))
cor.beta
inspect(cor.beta)
cor.beta <- tm_map(cor.beta, removeEnglish)
cor.beta <- tm_map(cor.beta, segmentCN)
library(Rwordseg)
cor.beta <- tm_map(cor.beta, segmentCN)
inspect(cor.beta)
cor.beta.dtm <- DocumentTermMatrix(cor.beta, control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
song.two <- lapply(song.two, removeEnglish)
song.two <- output$songLyric[1:2]
song.two <- lapply(song.two, removeEnglish)
song.two <- lapply(song.two,segmentCN)
song.two
cor.beta <- Corpus(VectorSource(song.two))
inspect(cor.beta)
cor.beta.dtm <- DocumentTermMatrix(cor.beta, control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
cor.beta.dtm
inspect(cor.beta.dtm)
cor.beta.dtm <- DocumentTermMatrix(cor.beta, control=list( wordLengths = c(2, Inf),stopwords=mystopwords,weighting = weightTfIdf))
inspect(cor.beta.dtm)
song.two <- lapply(song.two,segmentCN)
song.two
library(Rwordseg)
song.two <- lapply(song.two,segmentCN)
song.two <- output$songLyric[1:2]
song.two <- lapply(song.two, removeEnglish)
song.two <- lapply(song.two,segmentCN)
sont.two
song.two
inspect(cor.beta.dtm[1:5][1:5])
inspect(cor.beta.dtm)
library(tm)
inspect(cor.beta.dtm[1:5][1:5])
inspect(cor.beta.dtm)
a <- c(81,64,86,92,72,81)
median(a)
=======
install.packages("Rmongo")
install.packages("RMongo")
>>>>>>> 17f48d6010876fcd7407f266ddd7a17fd2ae03b7
library(RMongo)
library(tm)
library(topicmodels)
library(Rwordseg)
readerControl = list(reader = readPlain, language = "cn"))
source('~/.active-rstudio-document')
inspect(JJ)
JJ <- lapply(JJ, function(x) unlist(segmentCN(x)))
inspect(JJ)
inspect(JJ)
JJ
source('~/.active-rstudio-document')
inspect(temp)
removeURL <- function(x) {
gsub("http[[:alum:]]*", "", x)
}
##删除英语
removeEnglish <- function(x){
gsub("[a-z]+|[A-Z]+","",x)
}
temp <- tm_map(temp, removeURL)
temp <- tm_map(temp, removeEnglish)
temp <- tm_map(temp, stripWhitespace)
inspect(temp)
dtm <- DocumentTermMatrix(temp)
dtm
inspect(dtm)
mystopwords <- readline("stopwords.txt", encoding = "utf-8")
mystopwords <- readlines("stopwords.txt", encoding = "utf-8")
mystopwords <- readlines("stopwords.txt")
mystopwords <- readLines("stopwords.txt")
mystopwords
mystopwords <- readLines("stopwords.txt")
dtm <- DocumentTermMatrix(temp,control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
inspect(dtm)
dtm <- removeSparseTerms(dtm, 0.83)
dim(dtm)
dtm
inspect(dtm)
findFreqTerms(dtm, 5)
dtm <- DocumentTermMatrix(temp,control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
findFreqTerms(dtm, 5)
findFreqTerms(dtm, 2)
findFreqTerms(dtm, 1)
inspect(dtm)
?setdiff
?unlist
str(dbGetQuery)
?dbGetQuery
output <- dbGetQuery(mongo, 'song', "", limit = 2000)
mongo<-mongoDbConnect("mydb","localhost",27017)
output <- dbGetQuery(mongo, 'song', "", limit = 2000)
output <- dbGetQuery(mongo, 'song', "")
song <- output$songLyric
song
song <- lapply(song, removeEnglish)
##分词
word <- lapply(song,segmentCN)
word
cor <- Corpus(VectorSource(word))
inspect(cor)
cor[[1]]
source('~/.active-rstudio-document')
JJ  <- Corpus(DirSource("JJ"), encoding = "UTF-8",
readerControl = list(reader = readPlain, language = "cn"))
# 分词后为列表
JJ <- lapply(JJ, function(x) unlist(segmentCN(x)))
# 再组合成语料库
temp <- Corpus(VectorSource(JJ), encoding = "UTF-8",
readerControl = list(reader = readPlain, language = "cn"))
inspect(temp)
cor.dtm <- DocumentTermMatrix(cor, control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
cor.dtm <- removeSparseTerms(cor.dtm, 0.99)
cor.dtm
inspect(cor.dtm)
dim(cor.dtm)
rowTotals <- apply(cor.dtm, 1, sum)
cor.dtm <- cor.dtm[rowTotals > 0]
dim(cor.dtm)
findFreqTerms(cor.dtm, 5)
install.packages("wordcloud")
library(wordcloud)
install.packages("wordcloud")
install.packages("wordcloud")
library(wordcloud)
m <- as.matrix(t(cor.dtm))
wordFreq <- sort(rowSums(m), decreasing=TRUE)
wordcloud(words = names(wordFreq),freq = wordFreq,
random.order = F, colors = brewer.pal(8, "Dark2"))
install.packages("igraph")
library(igraph)
Tdtm <- t(dtm)
mdtm <- as.matrix(Tdtm)
mdtm[mdtm>-1]<- -1
termMatrix <- mdtm %*% t(mdtm)
g <- graph.adjacency(termMatrix, weighted=T, mode = 'undireacted')
g <- simplify(g)
v(g)$label <- v(g)$name
v(g)$degreee <- degree(g)
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
tkplot(g, layout-layout1)
g <- graph.adjacency(termMatrix, weighted=T, mode = 'undirected')
g <- simplify(g)
v(g)$label <- v(g)$name
V(g)$label <- V(g)$name
V(g)$degreee <- degree(g)
set.seed(3952)
layout1 <- layout.fruchterman.reingold(g)
tkplot(g, layout-layout1)
tkplot(g, layout=layout1)
tkplot(g, layout=layout1)
##取前面两首歌分析
song <- output$songLyric
## 分词
##删除英语
removeEnglish <- function(x){
gsub("[a-z]+|[A-Z]+","",x)
}
song <- lapply(song, removeEnglish)
##分词
word <- lapply(song,segmentCN)
##形成语料库
cor <- Corpus(VectorSource(word))
## 文档-词矩阵 词的长度大于1就纳入矩阵  TFIDF
mystopwords <- readLines("stopwords.txt")
cor.dtm <- DocumentTermMatrix(cor, control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
##去掉稀疏矩阵中低频率的词
cor.dtm <- removeSparseTerms(cor.dtm, 0.99)
## 使得每一行至少有一个词不为0
rowTotals <- apply(cor.dtm, 1, sum)
cor.dtm <- cor.dtm[rowTotals > 0]
findFreqTerms(cor.dtm, 5)
#词云分析
m <- as.matrix(t(cor.dtm))
wordFreq <- sort(rowSums(m), decreasing=TRUE)
wordcloud(words = names(wordFreq),freq = wordFreq,
random.order = F, colors = brewer.pal(8, "Dark2"))
warnings()
library(RMongo)
library(tm)
library(topicmodels)
library(Rwordseg)
library(wordcloud)
library(igraph)
##取前面两首歌分析
song <- output$songLyric
## 分词
##删除英语
removeEnglish <- function(x){
gsub("[a-z]+|[A-Z]+","",x)
}
song <- lapply(song, removeEnglish)
##分词
word <- lapply(song,segmentCN)
##形成语料库
cor <- Corpus(VectorSource(word))
## 文档-词矩阵 词的长度大于1就纳入矩阵  TFIDF
mystopwords <- readLines("stopwords.txt")
cor.dtm <- DocumentTermMatrix(cor, control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
##去掉稀疏矩阵中低频率的词
cor.dtm <- removeSparseTerms(cor.dtm, 0.99)
## 使得每一行至少有一个词不为0
rowTotals <- apply(cor.dtm, 1, sum)
cor.dtm <- cor.dtm[rowTotals > 0]
findFreqTerms(cor.dtm, 5)
#词云分析
m <- as.matrix(t(cor.dtm))
wordFreq <- sort(rowSums(m), decreasing=TRUE)
wordcloud(words = names(wordFreq),freq = wordFreq,
random.order = F, colors = brewer.pal(8, "Dark2"))
##取前面两首歌分析
song <- output$songLyric
## 分词
##删除英语
removeEnglish <- function(x){
gsub("[a-z]+|[A-Z]+","",x)
}
song <- lapply(song, removeEnglish)
##分词
word <- lapply(song,segmentCN)
##形成语料库
cor <- Corpus(VectorSource(word))
## 文档-词矩阵 词的长度大于1就纳入矩阵  TFIDF
mystopwords <- readLines("stopwords.txt")
cor.dtm <- DocumentTermMatrix(cor, control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
##去掉稀疏矩阵中低频率的词
cor.dtm <- removeSparseTerms(cor.dtm, 0.99)
## 使得每一行至少有一个词不为0
rowTotals <- apply(cor.dtm, 1, sum)
cor.dtm <- cor.dtm[rowTotals > 0]
findFreqTerms(cor.dtm, 5)
#词云分析
m <- as.matrix(t(cor.dtm))
wordFreq <- sort(rowSums(m), decreasing=TRUE)
wordcloud(words = names(wordFreq),freq = wordFreq,
random.order = F, colors = brewer.pal(8, "Dark2"))
##取前面两首歌分析
song <- output$songLyric
## 分词
##删除英语
removeEnglish <- function(x){
gsub("[a-z]+|[A-Z]+","",x)
}
song <- lapply(song, removeEnglish)
##分词
word <- lapply(song,segmentCN)
##形成语料库
cor <- Corpus(VectorSource(word))
## 文档-词矩阵 词的长度大于1就纳入矩阵  TFIDF
mystopwords <- readLines("stopwords.txt")
cor.dtm <- DocumentTermMatrix(cor, control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
##去掉稀疏矩阵中低频率的词
cor.dtm <- removeSparseTerms(cor.dtm, 0.99)
## 使得每一行至少有一个词不为0
rowTotals <- apply(cor.dtm, 1, sum)
cor.dtm <- cor.dtm[rowTotals > 0]
findFreqTerms(cor.dtm, 5)
#词云分析
m <- as.matrix(t(cor.dtm))
wordFreq <- sort(rowSums(m), decreasing=TRUE)
wordcloud(words = names(wordFreq),freq = wordFreq,
random.order = F, colors = brewer.pal(8, "Dark2"))
##取前面两首歌分析
song <- output$songLyric
## 分词
##删除英语
removeEnglish <- function(x){
gsub("[a-z]+|[A-Z]+","",x)
}
song <- lapply(song, removeEnglish)
##分词
word <- lapply(song,segmentCN)
##形成语料库
cor <- Corpus(VectorSource(word))
## 文档-词矩阵 词的长度大于1就纳入矩阵  TFIDF
mystopwords <- readLines("stopwords.txt")
cor.dtm <- DocumentTermMatrix(cor, control=list( wordLengths = c(1, Inf),stopwords=mystopwords,weighting = weightTfIdf))
##去掉稀疏矩阵中低频率的词
cor.dtm <- removeSparseTerms(cor.dtm, 0.99)
## 使得每一行至少有一个词不为0
rowTotals <- apply(cor.dtm, 1, sum)
cor.dtm <- cor.dtm[rowTotals > 0]
findFreqTerms(cor.dtm, 5)
#词云分析
m <- as.matrix(t(cor.dtm))
wordFreq <- sort(rowSums(m), decreasing=TRUE)
wordcloud(words = names(wordFreq),freq = wordFreq,
random.order = F, colors = brewer.pal(8, "Dark2"))
install.packages("Cairo")
library(Cario)
library(Cairo)
CairoPDF()
m <- as.matrix(t(cor.dtm))
wordFreq <- sort(rowSums(m), decreasing=TRUE)
wordcloud(words = names(wordFreq),freq = wordFreq,
random.order = F, colors = brewer.pal(8, "Dark2"))
dev.off()
library(wordcloud)
CairoPDF()
m <- as.matrix(t(cor.dtm))
wordFreq <- sort(rowSums(m), decreasing=TRUE)
wordcloud(words = names(wordFreq),freq = wordFreq,
random.order = F, colors = brewer.pal(8, "Dark2"))
dev.off()
library(tm)
inspect(cor.dtm)
meta(cor.dtm)
meta(cor[[1]])
cor[[1]]
m <- as.matrix(t(cor.dtm))
wordFreq <- sort(rowSums(m), decreasing=TRUE)
wordcloud(words = names(wordFreq),freq = wordFreq,
random.order = F, colors = brewer.pal(8, "Dark2"))
library(RMongo)
library(tm)
library(topicmodels)
library(Rwordseg)
library(wordcloud)
library(igraph)
m <- as.matrix(t(cor.dtm))
wordFreq <- sort(rowSums(m), decreasing=TRUE)
wordcloud(words = names(wordFreq),freq = wordFreq,
random.order = F, colors = brewer.pal(8, "Dark2"))
DublinCore(cor[[1]], "singer") <- "李玟"
DublinCore(cor[[1]], "description") <- "李玟"
meta(cor[[1]])
